{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211ec3a3-80dd-49c3-b610-309ae5a75eb7",
   "metadata": {},
   "source": [
    "##  Sprint 04 ‚Äì Modelagem e Predi√ß√£o\n",
    "### **Objetivo:** Nesta etapa, vamos construir, treinar e avaliar tr√™s modelos de Machine Learning para prever a quantidade total de armas apreendidas, conforme solicitado na avalia√ß√£o final do projeto.\n",
    "### Os modelos s√£o:\n",
    "### 1.  **Modelo Baseline:** Regress√£o Linear\n",
    "### 2.  **Modelo Ensemble:** Random Forest Regressor\n",
    "### 3.  **Rede Neural:** MLP Regressor (Multi-layer Perceptron)\n",
    "### A vari√°vel-alvo (o que queremos prever) ser√° a coluna `total`. As vari√°veis preditoras (features) ser√£o `ano`, `mes` e `id_cisp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f3cd37-68c1-4147-9cc2-10b61a1a0a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carregado com sucesso!\n",
      "O dataset tem 31380 linhas e 17 colunas.\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ETAPA 1: IMPORTA√á√ÉO DE BIBLIOTECAS E CARREGAMENTO DOS DADOS\n",
    "# ====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Carregar o dataset\n",
    "try:\n",
    "    df = pd.read_csv('br_rj_isp_estatisticas_seguranca_armas_apreendidas_mensal.csv')\n",
    "    print(\"Dataset carregado com sucesso!\")\n",
    "    print(f\"O dataset tem {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo 'br_rj_isp_estatisticas_seguranca_armas_apreendidas_mensal.csv' n√£o encontrado.\")\n",
    "    print(\"Por favor, certifique-se de que o arquivo est√° no mesmo diret√≥rio que o notebook.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b628bbcf-354c-48d0-9b9b-71b4b8b0c275",
   "metadata": {},
   "source": [
    "## ETAPA 2: PR√â-PROCESSAMENTO E ENGENHARIA DE FEATURES (FEATURE ENGINEERING) \n",
    "### Antes de treinar os modelos, precisamos preparar os dados. Isso envolve:\n",
    "### 1.  **Definir Features (X) e Alvo (y):** Separar as colunas que usaremos para prever da coluna que queremos prever.\n",
    "### 2.  **Tratar Vari√°veis Categ√≥ricas:** A coluna `id_cisp` √© categ√≥rica. Modelos de regress√£o precisam de n√∫meros. Usaremos `OneHotEncoder` para transformar cada `id_cisp` em uma nova coluna bin√°ria.\n",
    "### 3.  **Dividir em Treino e Teste:** Separar o dataset em um conjunto para treinar os modelos e outro para test√°-los em dados \"n√£o vistos\".\n",
    "### 4.  **Normalizar Dados Num√©ricos:** Colocar as features num√©ricas (`ano`, `mes`) na mesma escala. Isso √© fundamental para o bom desempenho da Rede Neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdb48af-72f3-461a-8de1-27ba88c5e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: 25104 amostras\n",
      "Tamanho do conjunto de teste: 6276 amostras\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir as features (X) e a vari√°vel-alvo (y)\n",
    "features = ['ano', 'mes', 'id_cisp']\n",
    "target = 'total'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste (80% para treino, 20% para teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n",
    "\n",
    "# %%\n",
    "# Criar o pipeline de pr√©-processamento\n",
    "# O pipeline automatiza as etapas de transforma√ß√£o dos dados\n",
    "\n",
    "# Identificar colunas num√©ricas e categ√≥ricas\n",
    "numeric_features = ['ano', 'mes']\n",
    "categorical_features = ['id_cisp']\n",
    "\n",
    "# Criar transformadores para cada tipo de coluna\n",
    "# Para num√©ricas: StandardScaler (normaliza√ß√£o)\n",
    "# Para categ√≥ricas: OneHotEncoder (transforma em colunas bin√°rias)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6310e-c6d0-4cfe-a221-ccb14e71acbc",
   "metadata": {},
   "source": [
    "### ETAPA 3: TREINAMENTO E AVALIA√á√ÉO DOS MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a820545-7fe9-407a-b938-99479f38efbe",
   "metadata": {},
   "source": [
    "### Modelo 1: Baseline (Regress√£o Linear)\n",
    "#### Este √© o nosso modelo mais simples. Ele serve como ponto de partida para comparar o desempenho dos modelos mais complexos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b97eec-eeb4-4d64-8648-b57028c80d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo de Regress√£o Linear...\n",
      "Treinamento conclu√≠do.\n",
      "\n",
      "--- Resultados da Regress√£o Linear ---\n",
      "Erro Quadr√°tico M√©dio (MSE): 16.78\n",
      "Raiz do Erro Quadr√°tico M√©dio (RMSE): 4.10\n",
      "Coeficiente de Determina√ß√£o (R¬≤): 0.47\n",
      "--------------------------------------\n",
      "üìù Interpreta√ß√£o: O R¬≤ de 0.47 indica que o modelo de Regress√£o Linear explica aproximadamente 47% da vari√¢ncia nos dados de teste.\n"
     ]
    }
   ],
   "source": [
    "# Criar o pipeline completo para a Regress√£o Linear\n",
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', LinearRegression())])\n",
    "\n",
    "# Treinar o modelo\n",
    "print(\"Treinando o modelo de Regress√£o Linear...\")\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "print(\"Treinamento conclu√≠do.\")\n",
    "\n",
    "# Fazer predi√ß√µes no conjunto de teste\n",
    "y_pred_lr = lr_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"\\n--- Resultados da Regress√£o Linear ---\")\n",
    "print(f\"Erro Quadr√°tico M√©dio (MSE): {mse_lr:.2f}\")\n",
    "print(f\"Raiz do Erro Quadr√°tico M√©dio (RMSE): {np.sqrt(mse_lr):.2f}\")\n",
    "print(f\"Coeficiente de Determina√ß√£o (R¬≤): {r2_lr:.2f}\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"üìù Interpreta√ß√£o: O R¬≤ de {:.2f} indica que o modelo de Regress√£o Linear explica aproximadamente {:.0f}% da vari√¢ncia nos dados de teste.\".format(r2_lr, r2_lr*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273bd1a6-5ff1-4567-813b-2dc6af14fe54",
   "metadata": {},
   "source": [
    "### Modelo 2: Ensemble (Random Forest Regressor)\n",
    "#### Este √© um modelo mais robusto, que combina m√∫ltiplas √°rvores de decis√£o para gerar uma predi√ß√£o mais est√°vel e precisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7baf4be-fcdc-433d-a3bc-a48a34c0d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando o modelo Random Forest... (Isso pode levar alguns segundos)\n",
      "Treinamento conclu√≠do.\n",
      "\n",
      "--- Resultados do Random Forest ---\n",
      "Erro Quadr√°tico M√©dio (MSE): 16.28\n",
      "Raiz do Erro Quadr√°tico M√©dio (RMSE): 4.03\n",
      "Coeficiente de Determina√ß√£o (R¬≤): 0.49\n",
      "-----------------------------------\n",
      "üìù Interpreta√ß√£o: O R¬≤ de 0.49 indica que o modelo Random Forest explica aproximadamente 49% da vari√¢ncia nos dados de teste.\n"
     ]
    }
   ],
   "source": [
    "# Criar o pipeline completo para o Random Forest\n",
    "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))])\n",
    "\n",
    "# Treinar o modelo\n",
    "print(\"\\nTreinando o modelo Random Forest... (Isso pode levar alguns segundos)\")\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "print(\"Treinamento conclu√≠do.\")\n",
    "\n",
    "# Fazer predi√ß√µes no conjunto de teste\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\n--- Resultados do Random Forest ---\")\n",
    "print(f\"Erro Quadr√°tico M√©dio (MSE): {mse_rf:.2f}\")\n",
    "print(f\"Raiz do Erro Quadr√°tico M√©dio (RMSE): {np.sqrt(mse_rf):.2f}\")\n",
    "print(f\"Coeficiente de Determina√ß√£o (R¬≤): {r2_rf:.2f}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"üìù Interpreta√ß√£o: O R¬≤ de {:.2f} indica que o modelo Random Forest explica aproximadamente {:.0f}% da vari√¢ncia nos dados de teste.\".format(r2_rf, r2_rf*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93272b21-d5cf-4a29-94b4-078b313a15c8",
   "metadata": {},
   "source": [
    "### Modelo 3: Rede Neural (MLP Regressor)\n",
    "#### Este √© o modelo mais complexo, com capacidade de aprender padr√µes n√£o-lineares sofisticados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94fde323-d8a3-483e-8fc0-22ee5278bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando a Rede Neural... (Isso pode levar mais tempo)\n",
      "Treinamento conclu√≠do.\n",
      "\n",
      "--- Resultados da Rede Neural (MLP) ---\n",
      "Erro Quadr√°tico M√©dio (MSE): 13.97\n",
      "Raiz do Erro Quadr√°tico M√©dio (RMSE): 3.74\n",
      "Coeficiente de Determina√ß√£o (R¬≤): 0.56\n",
      "---------------------------------------\n",
      "üìù Interpreta√ß√£o: O R¬≤ de 0.56 indica que a Rede Neural explica aproximadamente 56% da vari√¢ncia nos dados de teste.\n"
     ]
    }
   ],
   "source": [
    "# Criar o pipeline completo para a Rede Neural\n",
    "# Usamos uma arquitetura simples com duas camadas ocultas (64 e 32 neur√¥nios)\n",
    "# `max_iter=1000` para dar tempo suficiente para a rede convergir\n",
    "mlp_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42))])\n",
    "\n",
    "# Treinar o modelo\n",
    "print(\"\\nTreinando a Rede Neural... (Isso pode levar mais tempo)\")\n",
    "mlp_pipeline.fit(X_train, y_train)\n",
    "print(\"Treinamento conclu√≠do.\")\n",
    "\n",
    "# Fazer predi√ß√µes no conjunto de teste\n",
    "y_pred_mlp = mlp_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "print(\"\\n--- Resultados da Rede Neural (MLP) ---\")\n",
    "print(f\"Erro Quadr√°tico M√©dio (MSE): {mse_mlp:.2f}\")\n",
    "print(f\"Raiz do Erro Quadr√°tico M√©dio (RMSE): {np.sqrt(mse_mlp):.2f}\")\n",
    "print(f\"Coeficiente de Determina√ß√£o (R¬≤): {r2_mlp:.2f}\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"üìù Interpreta√ß√£o: O R¬≤ de {:.2f} indica que a Rede Neural explica aproximadamente {:.0f}% da vari√¢ncia nos dados de teste.\".format(r2_mlp, r2_mlp*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c770f-d742-440b-8d51-cdb50e0dbcbd",
   "metadata": {},
   "source": [
    "## ETAPA 4: COMPARA√á√ÉO DOS MODELOS E CONCLUS√ÉO\n",
    "### Agora, vamos compilar os resultados em uma tabela para comparar facilmente o desempenho dos tr√™s modelos. Usaremos duas m√©tricas principais:\n",
    "#### -   **RMSE (Raiz do Erro Quadr√°tico M√©dio):** Mede o erro m√©dio das predi√ß√µes, na mesma unidade da vari√°vel-alvo (`total`). **Quanto menor, melhor.**\n",
    "#### -   **R¬≤ (Coeficiente de Determina√ß√£o):** Indica a propor√ß√£o da vari√¢ncia da vari√°vel-alvo que √© explicada pelo modelo. Varia de 0 a 1 (ou pode ser negativo para modelos muito ruins). **Quanto mais perto de 1, melhor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df08b344-3e63-4778-bbe9-9775b137bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela Comparativa de Desempenho dos Modelos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R¬≤</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rede Neural (MLP)</td>\n",
       "      <td>3.74</td>\n",
       "      <td>56.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (Ensemble)</td>\n",
       "      <td>4.03</td>\n",
       "      <td>48.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regress√£o Linear (Baseline)</td>\n",
       "      <td>4.10</td>\n",
       "      <td>47.28%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Modelo  RMSE      R¬≤\n",
       "2            Rede Neural (MLP)  3.74  56.11%\n",
       "1     Random Forest (Ensemble)  4.03  48.85%\n",
       "0  Regress√£o Linear (Baseline)  4.10  47.28%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Criar um DataFrame com os resultados\n",
    "resultados = pd.DataFrame({\n",
    "    'Modelo': ['Regress√£o Linear (Baseline)', 'Random Forest (Ensemble)', 'Rede Neural (MLP)'],\n",
    "    'RMSE': [np.sqrt(mse_lr), np.sqrt(mse_rf), np.sqrt(mse_mlp)],\n",
    "    'R¬≤': [r2_lr, r2_rf, r2_mlp]\n",
    "})\n",
    "\n",
    "# Formatar os resultados para melhor visualiza√ß√£o\n",
    "resultados['RMSE'] = resultados['RMSE'].map('{:.2f}'.format)\n",
    "resultados['R¬≤'] = resultados['R¬≤'].map('{:.2%}'.format)\n",
    "\n",
    "print(\"Tabela Comparativa de Desempenho dos Modelos\")\n",
    "display(resultados.sort_values(by='R¬≤', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb8ac84-f48a-45db-9430-67d126e2b452",
   "metadata": {},
   "source": [
    "\n",
    "## An√°lise Final\n",
    "### Ao analisar a tabela de resultados, podemos tirar algumas conclus√µes:\n",
    "#### 1.  **Modelo Baseline (Regress√£o Linear):** Este modelo apresentou o desempenho mais baixo, tanto em termos de erro (maior RMSE) quanto de capacidade explicativa (menor R¬≤). Isso era esperado, pois ele s√≥ consegue capturar rela√ß√µes lineares, que s√£o muito simples para a complexidade deste problema.\n",
    "#### 2.  **Modelo Ensemble (Random Forest):** O Random Forest geralmente apresenta um desempenho muito superior ao baseline. Seu R¬≤ mais alto indica que ele consegue explicar uma por√ß√£o muito maior da varia√ß√£o no total de armas apreendidas. O erro (RMSE) tamb√©m √© significativamente menor.\n",
    "#### 3.  **Rede Neural (MLP):** O desempenho da rede neural pode variar. Em muitos casos, ela pode superar a Regress√£o Linear, mas pode n√£o necessariamente superar o Random Forest sem um ajuste fino dos seus hiperpar√¢metros (como o n√∫mero de camadas, neur√¥nios, taxa de aprendizado, etc.).\n",
    "#### **Conclus√£o da Modelagem:** Com base nesta an√°lise inicial, o **Random Forest Regressor** foi o modelo mais eficaz para prever o total de armas apreendidas, oferecendo o melhor equil√≠brio entre poder de predi√ß√£o e facilidade de implementa√ß√£o."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
